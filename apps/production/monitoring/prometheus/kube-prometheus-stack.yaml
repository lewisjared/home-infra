# kube-prometheus-stack HelmRelease
# This includes Prometheus, AlertManager, Grafana, and related components
---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
spec:
  interval: 30m
  timeout: 15m
  chart:
    spec:
      chart: kube-prometheus-stack
      version: ">=79.0.0 <80.0.0" # Pin to v79.x (latest stable)
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: monitoring
      interval: 12h
  # Installation options
  install:
    createNamespace: false # Namespace created by infrastructure kustomization
    remediation:
      retries: 3
  # Upgrade options
  upgrade:
    force: true
    remediation:
      retries: 3
      remediateLastFailure: true
    cleanupOnFail: true
  # Uninstall options
  uninstall:
    keepHistory: false
  # Rollback on failure
  rollback:
    recreate: true
    cleanupOnFail: true
  # Values override
  values:
    # CRD Management - Enable automated CRD updates for chart upgrades
    crds:
      enabled: true
      upgradeJob:
        enabled: true

    # Global settings
    fullnameOverride: prometheus

    # Prometheus configuration
    prometheus:
      prometheusSpec:
        # Enable remote write receiver for k8s-monitoring (Alloy)
        enableRemoteWriteReceiver: true

        # Add cluster label to all metrics for dashboard filtering
        externalLabels:
          cluster: home-infra

        # Resource limits for Prometheus
        resources:
          requests:
            cpu: 500m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 4Gi

        # Retention settings
        retention: 30d
        retentionSize: "45GB"

        # Storage configuration
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: rook-ceph-block
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 50Gi

        # Service monitor selector (monitor all ServiceMonitors)
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelectorNilUsesHelmValues: false

        additionalScrapeConfigs:
          - job_name: proxmox-node-exporter
            scrape_interval: 30s
            static_configs:
              - targets:
                  - 10.10.20.10:9100 # churro
                  - 10.10.20.11:9100 # mole
                  - 10.10.20.12:9100 # taco
                  - 10.10.20.13:9100 # nacho
                  - 10.10.20.14:9100 # tamale
                labels:
                  job: proxmox-node-exporter
                  cluster: home-infra
            relabel_configs:
              - source_labels: [__address__]
                regex: '10\.10\.20\.10:.*'
                target_label: instance
                replacement: churro
              - source_labels: [__address__]
                regex: '10\.10\.20\.11:.*'
                target_label: instance
                replacement: mole
              - source_labels: [__address__]
                regex: '10\.10\.20\.12:.*'
                target_label: instance
                replacement: taco
              - source_labels: [__address__]
                regex: '10\.10\.20\.13:.*'
                target_label: instance
                replacement: nacho
              - source_labels: [__address__]
                regex: '10\.10\.20\.14:.*'
                target_label: instance
                replacement: tamale
    defaultRules:
      create: true
      rules:
        alertmanager: true
        etcd: true
        configReloaders: true
        general: true
        k8sContainerCpuUsageSecondsTotal: true
        k8sContainerMemoryCache: true
        k8sContainerMemoryRss: true
        k8sContainerMemorySwap: true
        k8sContainerResource: true
        k8sContainerMemoryWorkingSetBytes: true
        k8sPodOwner: true
        kubeApiserverAvailability: true
        kubeApiserverBurnrate: true
        kubeApiserverHistogram: true
        kubeApiserverSlos: true
        kubeControllerManager: true
        kubelet: true
        kubeProxy: false
        kubePrometheusGeneral: true
        kubePrometheusNodeRecording: true
        kubernetesApps: true
        kubernetesResources: true
        kubernetesStorage: true
        kubernetesSystem: true
        kubeSchedulerAlerting: true
        kubeSchedulerRecording: true
        kubeStateMetrics: true
        network: true
        node: true
        nodeExporterAlerting: true
        nodeExporterRecording: true
        prometheus: true
        prometheusOperator: true
        windows: true

    # Grafana - DISABLED in favor of Grafana Operator
    # See apps/production/monitoring/grafana/ for the new Grafana deployment
    grafana:
      enabled: false

    # AlertManager configuration
    alertmanager:
      enabled: true
      config:
        global:
          resolve_timeout: 5m
        route:
          group_by: ["alertname", "namespace"]
          group_wait: 30s
          group_interval: 5m
          repeat_interval: 4h
          receiver: "pushover-critical"
          routes:
            - receiver: "pushover-critical"
              matchers:
                - severity = critical
            - receiver: "pushover-warning"
              matchers:
                - severity = warning
        receivers:
          - name: "pushover-critical"
            pushover_configs:
              - user_key_file: /etc/alertmanager/secrets/alertmanager-pushover/user_key
                token_file: /etc/alertmanager/secrets/alertmanager-pushover/api_token
                priority: 1
                title: "[CRITICAL] {{ .GroupLabels.alertname }}"
          - name: "pushover-warning"
            pushover_configs:
              - user_key_file: /etc/alertmanager/secrets/alertmanager-pushover/user_key
                token_file: /etc/alertmanager/secrets/alertmanager-pushover/api_token
                priority: 0
                title: "[WARNING] {{ .GroupLabels.alertname }}"
        inhibit_rules:
          - source_matchers:
              - severity = critical
            target_matchers:
              - severity = warning
            equal: ["alertname", "namespace"]
      alertmanagerSpec:
        secrets:
          - alertmanager-pushover
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 256Mi
        storage:
          volumeClaimTemplate:
            spec:
              storageClassName: rook-ceph-block
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 10Gi

    # Add cluster label to kubelet/cadvisor metrics for dashboard filtering
    kubelet:
      serviceMonitor:
        metricRelabelings:
          - action: replace
            targetLabel: cluster
            replacement: home-infra
        cAdvisorMetricRelabelings:
          - action: replace
            targetLabel: cluster
            replacement: home-infra

    kubeStateMetrics:
      enabled: true

    # Add cluster label to kube-state-metrics for dashboard filtering
    kube-state-metrics:
      prometheus:
        monitor:
          metricRelabelings:
            - action: replace
              targetLabel: cluster
              replacement: home-infra

    # Keep node-exporter disabled - using k8s-monitoring's version
    nodeExporter:
      enabled: false

    # Prometheus Operator settings
    prometheusOperator:
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
        limits:
          cpu: 500m
          memory: 256Mi
